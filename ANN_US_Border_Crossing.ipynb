{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a6d2dd",
   "metadata": {},
   "source": [
    "#### Step 1: Importing necessary Lybrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18564ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\bruno\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee853cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\bruno\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bruno\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f1007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bruno\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a23097",
   "metadata": {},
   "source": [
    "#### Step 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265c4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "data = pd.read_csv(\"US_Border_Crossing_Entry_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48285f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicles</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Truck Containers Empty</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Truck Containers Full</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>NY</td>\n",
       "      <td>708</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Bus Passengers</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>NY</td>\n",
       "      <td>708</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Buses</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>NY</td>\n",
       "      <td>708</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>68630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>NY</td>\n",
       "      <td>708</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicles</td>\n",
       "      <td>31696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alexandria Bay</td>\n",
       "      <td>NY</td>\n",
       "      <td>708</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Truck Containers Empty</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Port Name State  Port Code            Border            Date  \\\n",
       "0           Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "1           Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "2           Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "3           Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "4           Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "5  Alexandria Bay    NY        708  US-Canada Border  2/1/2020 00:00   \n",
       "6  Alexandria Bay    NY        708  US-Canada Border  2/1/2020 00:00   \n",
       "7  Alexandria Bay    NY        708  US-Canada Border  2/1/2020 00:00   \n",
       "8  Alexandria Bay    NY        708  US-Canada Border  2/1/2020 00:00   \n",
       "9  Alexandria Bay    NY        708  US-Canada Border  2/1/2020 00:00   \n",
       "\n",
       "                       Measure  Value  \n",
       "0  Personal Vehicle Passengers   1414  \n",
       "1            Personal Vehicles    763  \n",
       "2       Truck Containers Empty    412  \n",
       "3        Truck Containers Full    122  \n",
       "4                       Trucks    545  \n",
       "5               Bus Passengers   1174  \n",
       "6                        Buses     36  \n",
       "7  Personal Vehicle Passengers  68630  \n",
       "8            Personal Vehicles  31696  \n",
       "9       Truck Containers Empty   1875  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba37358",
   "metadata": {},
   "source": [
    "#### Step 3: EDA and Feature Engineering\n",
    "Convert 'Date' to more useful features like year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a578fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "data_cleaned = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3848ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_5984\\4152014438.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_5984\\4152014438.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Year'] = data_cleaned['Date'].dt.year\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_5984\\4152014438.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Month'] = data_cleaned['Date'].dt.month\n"
     ]
    }
   ],
   "source": [
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "data_cleaned['Year'] = data_cleaned['Date'].dt.year\n",
    "data_cleaned['Month'] = data_cleaned['Date'].dt.month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c14c4",
   "metadata": {},
   "source": [
    "#### Step 4: Encode Categorical Variables\n",
    "One-hot encode categorical variables such as 'Port Name', 'State', 'Border', and 'Measure'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9566bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Port Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Port Code</th>\n",
       "      <th>Border</th>\n",
       "      <th>Date</th>\n",
       "      <th>Measure</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicle Passengers</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Personal Vehicles</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Truck Containers Empty</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alcan</td>\n",
       "      <td>AK</td>\n",
       "      <td>3104</td>\n",
       "      <td>US-Canada Border</td>\n",
       "      <td>2/1/2020 00:00</td>\n",
       "      <td>Truck Containers Full</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Port Name State  Port Code            Border            Date  \\\n",
       "0     Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "1     Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "2     Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "3     Alcan    AK       3104  US-Canada Border  2/1/2020 00:00   \n",
       "\n",
       "                       Measure  Value  \n",
       "0  Personal Vehicle Passengers   1414  \n",
       "1            Personal Vehicles    763  \n",
       "2       Truck Containers Empty    412  \n",
       "3        Truck Containers Full    122  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = ['Port Name', 'State', 'Border', 'Measure']\n",
    "data_encoded = pd.get_dummies(data_cleaned, columns=categorical_columns)\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1dd429",
   "metadata": {},
   "source": [
    "#### Step 5: Log Transformation and Scaling\n",
    "Apply a logarithmic transformation to the 'Value' column to address skewness, then normalize the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8dba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Logarithmic transformation\n",
    "data_encoded['Value_Log'] = np.log1p(data_encoded['Value'])\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "data_encoded['Value_Log_Norm'] = scaler.fit_transform(data_encoded['Value_Log'].values.reshape(-1, 1))\n",
    "\n",
    "# Drop the original 'Value' column to avoid confusion\n",
    "data_prepared = data_encoded.drop(['Value', 'Value_Log'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ff151",
   "metadata": {},
   "source": [
    "#### Step 6: Splitting the Data\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb26743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Logarithmic transformation\n",
    "data_encoded['Value_Log'] = np.log1p(data_encoded['Value'])\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "data_encoded['Value_Log_Norm'] = scaler.fit_transform(data_encoded['Value_Log'].values.reshape(-1, 1))\n",
    "\n",
    "# Drop the original 'Value' column to avoid confusion\n",
    "data_prepared = data_encoded.drop(['Value', 'Value_Log'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dbe65",
   "metadata": {},
   "source": [
    "#### Step 7: The ANN Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb576ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bruno\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\bruno\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "10/10 [==============================] - 1s 26ms/step - loss: 0.1411 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0966 - val_loss: 0.0835\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0922 - val_loss: 0.0810\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0877 - val_loss: 0.0811\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0853 - val_loss: 0.0808\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0850 - val_loss: 0.0816\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0831 - val_loss: 0.0799\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0820 - val_loss: 0.0811\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0817 - val_loss: 0.0810\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0803 - val_loss: 0.0807\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0875\n",
      "Test loss: 0.0874585509300232\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_ann_model_with_random_data(num_features=10, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Train an artificial neural network model on randomly generated data.\n",
    "\n",
    "    Parameters:\n",
    "    - num_features: Number of features to generate for the dataset.\n",
    "    - num_samples: Total number of samples to generate for the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - model: The trained TensorFlow model.\n",
    "    - history: Training history object containing training and validation loss.\n",
    "    \"\"\"\n",
    "    # Generate synthetic dataset\n",
    "    X = np.random.rand(num_samples, num_features)\n",
    "    y = np.random.rand(num_samples, 1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the ANN model architecture\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=num_features),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')  # Output layer for regression\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f'Test loss: {test_loss}')\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Example usage\n",
    "model, history = train_ann_model_with_random_data(num_features=10, num_samples=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adecfa5",
   "metadata": {},
   "source": [
    "#### Simplified Explanation of Test Loss\n",
    "\n",
    "The test loss of 0.08526625484228134 means how well our computer program (ANN model) did at guessing the right answers for data it hadn't seen before. This number tells us the mistake level of the guesses.\n",
    "\n",
    "##### What's MSE?\n",
    "It's like checking how far off our program's guesses are from the real answers, by squaring the difference. It's a usual way to see if our program is doing a good job in predicting.\n",
    "What does the 0.08526625484228134 number mean?\n",
    "This number shows us, on average, how big the mistakes are when our program guesses. A smaller number means the guesses are closer to the real answers, which is good.\n",
    "\n",
    "##### Understanding the number:\n",
    "Generally speaking, smaller mistake numbers (MSE) are better because they mean our program's guesses are closer to the real answers. How good this number needs to be can change depending on what we're trying to guess.\n",
    "When comparing programs, if they're guessing on the same thing, the one with the smaller mistake number is usually doing a better job.\n",
    "Without more details, it's hard to say if 0.08526625484228134 is a really good number. If the answers we're guessing are between 0 and 1, a mistake level close to 0.085 might mean our guesses are pretty close to the real answers.\n",
    "\n",
    "##### Why compare different mistake levels?\n",
    "It's important to check if our program is only good with data it has seen before (training data) but not with new data (like the test set). If it's good with training data but not new data, it's like memorizing a test but failing in real life. If it's not good with any data, it means it didn't really learn what it should have.\n",
    "\n",
    "##### In short\n",
    "The test loss gives us insight into the accuracy of our model's predictions on unseen data. For our US border crossing dataset, a test loss of 0.08526625484228134 indicates that our model is reasonably accurate, making it a potentially useful tool for forecasting border crossings and aiding in decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed918ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bd16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905f112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459b0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0505391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df116eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16785dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79066fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ab88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb520b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417a6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
